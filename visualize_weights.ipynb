{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python382jvsc74a57bd08973115da75745db42789df135534daed99c5f70f944bade3ce5259e320257cc",
      "display_name": "Python 3.8.2 64-bit ('tf': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "#Visualize weights, biases and network structure for float-model\n",
        "\n",
        "\n",
        "model_name = 'model_fc_1l_16'\n",
        "model = keras.models.load_model(f'models/'+model_name+'.h5', compile=False)\n",
        "\n",
        "w1 = model.layers[0].get_weights()[0]\n",
        "b1 = model.layers[0].get_weights()[1]\n",
        "w2 = model.layers[1].get_weights()[0]\n",
        "b2 = model.layers[1].get_weights()[1]\n",
        "\n",
        "\n",
        "print(w1.shape, b1.shape,w2.shape,b2.shape)\n",
        "print(np.min(w1),np.max(w1),np.median(w1))\n",
        "print(np.min(w2),np.max(w2),np.median(w2))\n",
        "\n",
        "\n",
        "for i in range(len(w1[0,:])):\n",
        "    plt.hist(w1[:,i], 75)\n",
        "plt.title('Histogram for the weights in float-values, hidden layer')\n",
        "plt.xlabel('weights (float32)')\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(w2[0,:])):\n",
        "    plt.hist(w2[:,i], 75)\n",
        "plt.title('Histogram for the weights in float-values, output layer')\n",
        "plt.xlabel('weights (float32)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "#Visualize weights, biases and network structure for quantized model\n",
        "\n",
        "\n",
        "model_name = 'model_fc_1l_16'\n",
        "w1 = np.load(f\"/home/luca/Documents/Project/models/quantized/weights_biases/\"+model_name+\"_weights_1.npy\") #shape(dim, 256)\n",
        "b1 = np.load(f\"/home/luca/Documents/Project/models/quantized/weights_biases/\"+model_name+\"_biases_1.npy\")\n",
        "w2 = np.load(f\"/home/luca/Documents/Project/models/quantized/weights_biases/\"+model_name+\"_weights_2.npy\") # shape(2, dim)\n",
        "b2 = np.load(f\"/home/luca/Documents/Project/models/quantized/weights_biases/\"+model_name+\"_biases_2.npy\")\n",
        "\n",
        "\n",
        "print(w1.shape, b1.shape,w2.shape,b2.shape)\n",
        "print(np.min(w1),np.max(w1),np.median(w1))\n",
        "print(np.min(w2),np.max(w2),np.median(w2))\n",
        "\n",
        "for i in range(len(w1[:,0])):\n",
        "    plt.hist(w1[i,:], 75)\n",
        "plt.title('Histogram for the quantized weights, hidden layer')\n",
        "plt.xlabel('weights (int8)')\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(w2[:,0])):\n",
        "    plt.hist(w2[i,:], 75)\n",
        "plt.title('Histogram for the quantized weights, output layer')\n",
        "plt.xlabel('weights (int8)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}